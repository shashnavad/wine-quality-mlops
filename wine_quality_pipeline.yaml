# PIPELINE DEFINITION
# Name: wine-quality-pipeline
# Description: End-to-end ML pipeline for wine quality prediction
# Inputs:
#    data_path: str [Default: 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv']
#    max_depth: int
#    min_samples_leaf: int [Default: 1.0]
#    min_samples_split: int [Default: 2.0]
#    n_estimators: int [Default: 100.0]
#    random_state: int [Default: 42.0]
components:
  comp-preprocess:
    executorLabel: exec-preprocess
    inputDefinitions:
      parameters:
        data_path:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        labels:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        scaler:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-train:
    executorLabel: exec-train
    inputDefinitions:
      artifacts:
        features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        labels:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        hyperparameters:
          parameterType: STRUCT
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-validate-data:
    executorLabel: exec-validate-data
    inputDefinitions:
      parameters:
        data_path:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-preprocess:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocess
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef preprocess(\n    data_path: str,\n    features: Output[Dataset],\n\
          \    labels: Output[Dataset],\n    scaler: Output[Model]\n):\n    \"\"\"\
          Preprocess the wine quality data.\"\"\"\n    # Load data\n    df = pd.read_csv(data_path,\
          \ sep=\";\")\n\n    # Split features and labels\n    X = df.drop('quality',\
          \ axis=1)\n    y = df['quality']\n\n    # Scale features\n    scaler_obj\
          \ = StandardScaler()\n    X_scaled = scaler_obj.fit_transform(X)\n\n   \
          \ # Save processed data\n    np.save(features.path, X_scaled)\n    np.save(labels.path,\
          \ y.values)\n    joblib.dump(scaler_obj, scaler.path)\n\n    print(f\"Preprocessed\
          \ features saved to {features.path}\")\n    print(f\"Preprocessed labels\
          \ saved to {labels.path}\")\n    print(f\"Scaler saved to {scaler.path}\"\
          )\n\n"
        image: pes1ug19cs601/wine-quality-mlops:latest
    exec-train:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train(\n    features: Input[Dataset],\n    labels: Input[Dataset],\n\
          \    hyperparameters: dict,\n    model: Output[Model],\n    metrics: Output[Metrics]\n\
          ):\n    \"\"\"Train a RandomForestRegressor model.\"\"\"\n    import os\n\
          \    import joblib\n    import json\n    import numpy as np\n    from sklearn.model_selection\
          \ import train_test_split\n    from sklearn.ensemble import RandomForestRegressor\n\
          \    import mlflow\n\n    # Load data\n    X = np.load(features.path)\n\
          \    y = np.load(labels.path)\n\n    # Split data\n    X_train, X_test,\
          \ y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\
          \n    # Train model\n    model_obj = RandomForestRegressor(**hyperparameters)\n\
          \    model_obj.fit(X_train, y_train)\n\n    # Evaluate model\n    train_score\
          \ = model_obj.score(X_train, y_train)\n    test_score = model_obj.score(X_test,\
          \ y_test)\n\n    # Save metrics\n    metrics_dict = {\n        'train_r2':\
          \ float(train_score),\n        'test_r2': float(test_score)\n    }\n   \
          \ with open(metrics.path, 'w') as f:\n        json.dump(metrics_dict, f,\
          \ indent=2)\n\n    # Save model\n    joblib.dump(model_obj, model.path)\n\
          \n    # Only log to MLflow if not in testing mode and if MLflow server is\
          \ available\n    if not os.environ.get(\"TESTING\", \"False\").lower() ==\
          \ \"true\":\n        try:\n            # Set a timeout for MLflow connection\
          \ attempts\n            import socket\n            socket.setdefaulttimeout(5)\
          \  # 5 second timeout\n\n            # Try to connect to MLflow server\n\
          \            mlflow.set_tracking_uri('http://mlflow-service.mlops.svc.cluster.local:5000')\n\
          \n            with mlflow.start_run():\n                mlflow.log_params(hyperparameters)\n\
          \                mlflow.log_metric(\"train_r2\", train_score)\n        \
          \        mlflow.log_metric(\"test_r2\", test_score)\n                mlflow.sklearn.log_model(model_obj,\
          \ \"model\")\n\n            print(\"Successfully logged metrics to MLflow\"\
          )\n        except Exception as e:\n            print(f\"MLflow logging failed\
          \ (this is expected in local environments): {e}\")\n            print(\"\
          Continuing without MLflow logging\")\n    else:\n        print(\"Testing\
          \ mode active, skipping MLflow logging\")\n\n    print(f\"Model saved to\
          \ {model.path}\")\n    print(f\"Metrics saved to {metrics.path}\")\n   \
          \ print(f\"Training metrics: {metrics_dict}\")\n\n"
        image: pes1ug19cs601/wine-quality-mlops:latest
    exec-validate-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - validate_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef validate_data(\n    data_path: str,\n    metrics: Output[Metrics]\n\
          ):\n    \"\"\"Validate wine data for drift using Great Expectations with\
          \ Git functionality disabled.\"\"\"\n    import os\n    import sys\n   \
          \ import json\n    import pandas as pd\n\n    import logging\n    # Configure\
          \ root logger and specific loggers to suppress debug messages\n    logging.getLogger().setLevel(logging.ERROR)\
          \  # Set root logger to ERROR\n    logging.getLogger('great_expectations').setLevel(logging.ERROR)\n\
          \    logging.getLogger('great_expectations.expectations.registry').setLevel(logging.CRITICAL)\
          \  # Even stricter for registry\n\n\n    # Set environment variables\n \
          \   os.environ[\"GE_USAGE_STATISTICS_ENABLED\"] = \"False\"\n    os.environ[\"\
          GE_UNCOMMITTED_DIRECTORIES\"] = \"True\"\n    os.environ[\"GX_ASSUME_MISSING_LIBRARIES\"\
          ] = \"git\"\n\n\n    # Import Great Expectations components\n    from great_expectations.data_context.types.base\
          \ import DataContextConfig\n    from great_expectations.data_context import\
          \ BaseDataContext\n    from great_expectations.core.batch import RuntimeBatchRequest\n\
          \n    try:\n        # Load data\n        print(\"Loading data...\")\n  \
          \      df = pd.read_csv(data_path)\n\n        # Create context configuration\n\
          \        print(\"Creating context configuration...\")\n        context_config\
          \ = DataContextConfig(\n            store_backend_defaults=None,\n     \
          \       checkpoint_store_name=None,\n            datasources={\n       \
          \         \"pandas_datasource\": {\n                    \"class_name\":\
          \ \"Datasource\",\n                    \"module_name\": \"great_expectations.datasource\"\
          ,\n                    \"execution_engine\": {\n                       \
          \ \"class_name\": \"PandasExecutionEngine\",\n                        \"\
          module_name\": \"great_expectations.execution_engine\"\n               \
          \     },\n                    \"data_connectors\": {\n                 \
          \       \"runtime_connector\": {\n                            \"class_name\"\
          : \"RuntimeDataConnector\",\n                            \"module_name\"\
          : \"great_expectations.datasource.data_connector\",\n                  \
          \          \"batch_identifiers\": [\"batch_id\"]\n                     \
          \   }\n                    }\n                }\n            }\n       \
          \ )\n\n        # Create context\n        print(\"Creating context...\")\n\
          \        context = BaseDataContext(project_config=context_config)\n\n  \
          \      # Create expectation suite\n        print(\"Creating expectation\
          \ suite...\")\n        suite_name = \"wine_quality_suite\"\n        context.create_expectation_suite(suite_name,\
          \ overwrite_existing=True)\n\n        # Create batch request\n        print(\"\
          Creating batch request...\")\n        batch_request = RuntimeBatchRequest(\n\
          \            datasource_name=\"pandas_datasource\",\n            data_connector_name=\"\
          runtime_connector\",\n            data_asset_name=\"wine_data\",\n     \
          \       runtime_parameters={\"batch_data\": df},\n            batch_identifiers={\"\
          batch_id\": \"default_identifier\"},\n        )\n\n        # Get validator\n\
          \        print(\"Getting validator...\")\n        validator = context.get_validator(\n\
          \            batch_request=batch_request,\n            expectation_suite_name=suite_name\n\
          \        )\n\n        # Add expectations\n        print(\"Adding expectations...\"\
          )\n        expectations = []\n\n        # Check that columns match expected\
          \ list\n        expectations.append(validator.expect_table_columns_to_match_ordered_list(list(df.columns)))\n\
          \n        # Check data types\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          fixed acidity\", \"float64\"))\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          volatile acidity\", \"float64\"))\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          citric acid\", \"float64\"))\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          residual sugar\", \"float64\"))\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          chlorides\", \"float64\"))\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          free sulfur dioxide\", \"float64\"))\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          total sulfur dioxide\", \"float64\"))\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          density\", \"float64\"))\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          pH\", \"float64\"))\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          sulphates\", \"float64\"))\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          alcohol\", \"float64\"))\n        expectations.append(validator.expect_column_values_to_be_of_type(\"\
          quality\", \"int64\"))\n\n        # Check value ranges\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          fixed acidity\", min_value=3.8, max_value=15.9))\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          volatile acidity\", min_value=0.08, max_value=1.58))\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          citric acid\", min_value=0, max_value=1.66))\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          residual sugar\", min_value=0.6, max_value=65.8))\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          chlorides\", min_value=0.009, max_value=0.611))\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          free sulfur dioxide\", min_value=1, max_value=289))\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          total sulfur dioxide\", min_value=6, max_value=440))\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          density\", min_value=0.98711, max_value=1.03898))\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          pH\", min_value=2.72, max_value=4.01))\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          sulphates\", min_value=0.22, max_value=2))\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          alcohol\", min_value=8, max_value=14.9))\n        expectations.append(validator.expect_column_values_to_be_between(\"\
          quality\", min_value=3, max_value=9))\n\n        # Check for missing values\n\
          \        for column in df.columns:\n            expectations.append(validator.expect_column_values_to_not_be_null(column))\n\
          \n        # Run validation\n        print(\"Running validation...\")\n \
          \       validation_results = validator.validate()\n\n        # Process results\n\
          \        print(\"Processing results...\")\n        validation_passed = validation_results.success\n\
          \n        # Prepare metrics\n        validation_metrics = {\n          \
          \  \"validation_success\": validation_passed,\n            \"evaluated_expectations\"\
          : validation_results.statistics[\"evaluated_expectations\"],\n         \
          \   \"successful_expectations\": validation_results.statistics[\"successful_expectations\"\
          ],\n            \"unsuccessful_expectations\": validation_results.statistics[\"\
          unsuccessful_expectations\"],\n        }\n\n        # Log metrics\n    \
          \    print(\"Logging metrics...\")\n        metrics.log_metric(\"validation_success\"\
          , float(validation_passed))\n        metrics.log_metric(\"evaluated_expectations\"\
          , float(validation_results.statistics[\"evaluated_expectations\"]))\n  \
          \      metrics.log_metric(\"successful_expectations\", float(validation_results.statistics[\"\
          successful_expectations\"]))\n        metrics.log_metric(\"unsuccessful_expectations\"\
          , float(validation_results.statistics[\"unsuccessful_expectations\"]))\n\
          \n        print(f\"Validation {'passed' if validation_passed else 'failed'}\"\
          )\n        print(f\"Metrics: {validation_metrics}\")\n\n        return validation_metrics\n\
          \n    except Exception as e:\n        print(f\"Error in validate_data: {type(e).__name__}:\
          \ {str(e)}\")\n        import traceback\n        print(traceback.format_exc())\n\
          \        # Log failure in metrics\n        metrics.log_metric(\"validation_success\"\
          , 0.0)\n        metrics.log_metric(\"error\", 1.0)\n        raise\n\n"
        image: pes1ug19cs601/wine-quality-mlops:latest
pipelineInfo:
  description: End-to-end ML pipeline for wine quality prediction
  name: wine-quality-pipeline
root:
  dag:
    tasks:
      preprocess:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-preprocess
        dependentTasks:
        - validate-data
        inputs:
          parameters:
            data_path:
              componentInputParameter: data_path
        taskInfo:
          name: preprocess
      train:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train
        dependentTasks:
        - preprocess
        inputs:
          artifacts:
            features:
              taskOutputArtifact:
                outputArtifactKey: features
                producerTask: preprocess
            labels:
              taskOutputArtifact:
                outputArtifactKey: labels
                producerTask: preprocess
          parameters:
            hyperparameters:
              runtimeValue:
                constant:
                  max_depth: '{{$.inputs.parameters[''pipelinechannel--max_depth'']}}'
                  min_samples_leaf: '{{$.inputs.parameters[''pipelinechannel--min_samples_leaf'']}}'
                  min_samples_split: '{{$.inputs.parameters[''pipelinechannel--min_samples_split'']}}'
                  n_estimators: '{{$.inputs.parameters[''pipelinechannel--n_estimators'']}}'
                  random_state: '{{$.inputs.parameters[''pipelinechannel--random_state'']}}'
            pipelinechannel--max_depth:
              componentInputParameter: max_depth
            pipelinechannel--min_samples_leaf:
              componentInputParameter: min_samples_leaf
            pipelinechannel--min_samples_split:
              componentInputParameter: min_samples_split
            pipelinechannel--n_estimators:
              componentInputParameter: n_estimators
            pipelinechannel--random_state:
              componentInputParameter: random_state
        taskInfo:
          name: train
      validate-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-validate-data
        inputs:
          parameters:
            data_path:
              componentInputParameter: data_path
        taskInfo:
          name: validate-data
  inputDefinitions:
    parameters:
      data_path:
        defaultValue: https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv
        isOptional: true
        parameterType: STRING
      max_depth:
        isOptional: true
        parameterType: NUMBER_INTEGER
      min_samples_leaf:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      min_samples_split:
        defaultValue: 2.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      n_estimators:
        defaultValue: 100.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      random_state:
        defaultValue: 42.0
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.12.1
