# PIPELINE DEFINITION
# Name: wine-quality-pipeline
# Description: End-to-end ML pipeline for wine quality prediction
# Inputs:
#    data_path: str [Default: 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv']
#    max_depth: int
#    min_samples_leaf: int [Default: 1.0]
#    min_samples_split: int [Default: 2.0]
#    n_estimators: int [Default: 100.0]
#    random_state: int [Default: 42.0]
components:
  comp-preprocess:
    executorLabel: exec-preprocess
    inputDefinitions:
      parameters:
        data_path:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        labels:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        scaler:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-train:
    executorLabel: exec-train
    inputDefinitions:
      artifacts:
        features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        labels:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        hyperparameters:
          parameterType: STRUCT
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-validate-data:
    executorLabel: exec-validate-data
    inputDefinitions:
      parameters:
        data_path:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-preprocess:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocess
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef preprocess(\n    data_path: str,\n    features: Output[Dataset],\n\
          \    labels: Output[Dataset],\n    scaler: Output[Model]\n):\n    \"\"\"\
          Preprocess the wine quality data.\"\"\"\n    # Load data\n    df = pd.read_csv(data_path,\
          \ sep=\";\")\n\n    # Split features and labels\n    X = df.drop('quality',\
          \ axis=1)\n    y = df['quality']\n\n    # Scale features\n    scaler_obj\
          \ = StandardScaler()\n    X_scaled = scaler_obj.fit_transform(X)\n\n   \
          \ # Save processed data\n    np.save(features.path, X_scaled)\n    np.save(labels.path,\
          \ y.values)\n    joblib.dump(scaler_obj, scaler.path)\n\n    print(f\"Preprocessed\
          \ features saved to {features.path}\")\n    print(f\"Preprocessed labels\
          \ saved to {labels.path}\")\n    print(f\"Scaler saved to {scaler.path}\"\
          )\n\n"
        image: pes1ug19cs601/wine-quality-mlops:latest
    exec-train:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train(\n    features: Input[Dataset],\n    labels: Input[Dataset],\n\
          \    hyperparameters: dict,\n    model: Output[Model],\n    metrics: Output[Metrics]\n\
          ):\n    \"\"\"Train a RandomForestRegressor model.\"\"\"\n    # Load data\n\
          \    X = np.load(features.path)\n    y = np.load(labels.path)\n\n    # Split\
          \ data\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\
          \ random_state=42)\n\n    # Train model\n    model_obj = RandomForestRegressor(**hyperparameters)\n\
          \    model_obj.fit(X_train, y_train)\n\n    # Evaluate model\n    train_score\
          \ = model_obj.score(X_train, y_train)\n    test_score = model_obj.score(X_test,\
          \ y_test)\n\n    # Save metrics\n    metrics_dict = {\n        'train_r2':\
          \ float(train_score),\n        'test_r2': float(test_score)\n    }\n   \
          \ with open(metrics.path, 'w') as f:\n        json.dump(metrics_dict, f,\
          \ indent=2)\n\n    # Save model\n    joblib.dump(model_obj, model.path)\n\
          \n    # Log to MLflow\n    mlflow.set_tracking_uri('http://mlflow-service.mlops.svc.cluster.local:5000')\n\
          \    with mlflow.start_run():\n        mlflow.log_params(hyperparameters)\n\
          \        mlflow.log_metric(\"train_r2\", train_score)\n        mlflow.log_metric(\"\
          test_r2\", test_score)\n        mlflow.sklearn.log_model(model_obj, \"model\"\
          )\n\n    print(f\"Model saved to {model.path}\")\n    print(f\"Metrics saved\
          \ to {metrics.path}\")\n    print(f\"Training metrics: {metrics_dict}\"\
          )\n\n"
        image: pes1ug19cs601/wine-quality-mlops:latest
    exec-validate-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - validate_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef validate_data(\n    data_path: str,\n    metrics: Output[Metrics]\n\
          ):\n    \"\"\"Validate wine data for drift using Great Expectations.\"\"\
          \"\n    import os\n    import sys\n    import json\n    import pandas as\
          \ pd\n    from great_expectations.data_context import DataContext\n\n  \
          \  # Try to initialize Great Expectations context\n    try:\n        # Check\
          \ if great_expectations directory exists in the current directory\n    \
          \    if not os.path.exists('great_expectations'):\n            from great_expectations.data_context.types.base\
          \ import DataContextConfig\n            from great_expectations.data_context\
          \ import BaseDataContext\n\n            # Create minimal config for in-memory\
          \ context\n            context_config = DataContextConfig(\n           \
          \     store_backend_defaults=None,\n                checkpoint_store_name=None,\n\
          \            )\n            context = BaseDataContext(project_config=context_config)\n\
          \n            # Create simple expectation suite programmatically\n     \
          \       suite = context.create_expectation_suite(\"wine_quality_suite\"\
          )\n\n            # Load the data to create expectations\n            df\
          \ = pd.read_csv(data_path, sep=\";\")\n            batch = context.get_batch({},\
          \ batch_data=df)\n\n            # Add basic expectations for wine data\n\
          \            batch.expect_table_columns_to_match_ordered_list(\n       \
          \         list(df.columns),\n                result_format=\"COMPLETE\"\n\
          \            )\n            batch.expect_column_values_to_be_between(\"\
          fixed acidity\", 4.0, 16.0)\n            batch.expect_column_values_to_be_between(\"\
          volatile acidity\", 0.1, 1.2)\n            batch.expect_column_values_to_be_between(\"\
          pH\", 2.7, 4.0)\n            batch.expect_column_values_to_be_between(\"\
          alcohol\", 8.0, 15.0)\n            batch.expect_column_values_to_be_between(\"\
          quality\", 3, 9)\n            batch.expect_column_mean_to_be_between(\"\
          alcohol\", 10.0, 11.5)\n\n            # Save expectation suite\n       \
          \     context.save_expectation_suite(suite)\n        else:\n           \
          \ # Use existing context\n            context = DataContext()\n\n      \
          \  # Load new data for validation\n        df = pd.read_csv(data_path, sep=\"\
          ;\")\n\n        # Create batch and validate\n        batch_kwargs = {\"\
          dataset\": df}\n        batch = context.get_batch(batch_kwargs, \"wine_quality_suite\"\
          )\n        results = context.run_validation_operator(\n            \"action_list_operator\"\
          ,\n            assets_to_validate=[batch],\n            run_id=\"wine_pipeline_run\"\
          \n        )\n\n        # Process validation results\n        validation_success\
          \ = results[\"success\"]\n        expectations_results = results[\"results\"\
          ][0][\"result\"]\n\n        # Count successful and failed expectations\n\
          \        expectations_total = len(expectations_results[\"results\"])\n \
          \       expectations_success = sum(1 for r in expectations_results[\"results\"\
          ] if r[\"success\"])\n\n        # Prepare metrics\n        metrics_dict\
          \ = {\n            \"validation_success\": validation_success,\n       \
          \     \"expectations_total\": expectations_total,\n            \"expectations_passed\"\
          : expectations_success,\n            \"success_rate\": expectations_success\
          \ / expectations_total if expectations_total > 0 else 0\n        }\n\n \
          \       # Save metrics\n        with open(metrics.path, 'w') as f:\n   \
          \         json.dump(metrics_dict, f, indent=2)\n\n        print(f\"Data\
          \ validation completed with success: {validation_success}\")\n        print(f\"\
          Passed {expectations_success} out of {expectations_total} expectations\"\
          )\n\n        # Optional: fail pipeline if validation fails\n        if not\
          \ validation_success:\n            print(\"WARNING: Data drift detected!\
          \ Check validation results.\")\n            # Uncomment to make pipeline\
          \ fail on drift detection\n            # raise ValueError(\"Data validation\
          \ failed - possible data drift detected\")\n\n    except Exception as e:\n\
          \        print(f\"Error during data validation: {str(e)}\")\n        # Save\
          \ error in metrics\n        with open(metrics.path, 'w') as f:\n       \
          \     json.dump({\"error\": str(e)}, f)\n        raise\n\n"
        image: pes1ug19cs601/wine-quality-mlops:latest
pipelineInfo:
  description: End-to-end ML pipeline for wine quality prediction
  name: wine-quality-pipeline
root:
  dag:
    tasks:
      preprocess:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-preprocess
        dependentTasks:
        - validate-data
        inputs:
          parameters:
            data_path:
              componentInputParameter: data_path
        taskInfo:
          name: preprocess
      train:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train
        dependentTasks:
        - preprocess
        inputs:
          artifacts:
            features:
              taskOutputArtifact:
                outputArtifactKey: features
                producerTask: preprocess
            labels:
              taskOutputArtifact:
                outputArtifactKey: labels
                producerTask: preprocess
          parameters:
            hyperparameters:
              runtimeValue:
                constant:
                  max_depth: '{{$.inputs.parameters[''pipelinechannel--max_depth'']}}'
                  min_samples_leaf: '{{$.inputs.parameters[''pipelinechannel--min_samples_leaf'']}}'
                  min_samples_split: '{{$.inputs.parameters[''pipelinechannel--min_samples_split'']}}'
                  n_estimators: '{{$.inputs.parameters[''pipelinechannel--n_estimators'']}}'
                  random_state: '{{$.inputs.parameters[''pipelinechannel--random_state'']}}'
            pipelinechannel--max_depth:
              componentInputParameter: max_depth
            pipelinechannel--min_samples_leaf:
              componentInputParameter: min_samples_leaf
            pipelinechannel--min_samples_split:
              componentInputParameter: min_samples_split
            pipelinechannel--n_estimators:
              componentInputParameter: n_estimators
            pipelinechannel--random_state:
              componentInputParameter: random_state
        taskInfo:
          name: train
      validate-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-validate-data
        inputs:
          parameters:
            data_path:
              componentInputParameter: data_path
        taskInfo:
          name: validate-data
  inputDefinitions:
    parameters:
      data_path:
        defaultValue: https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv
        isOptional: true
        parameterType: STRING
      max_depth:
        isOptional: true
        parameterType: NUMBER_INTEGER
      min_samples_leaf:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      min_samples_split:
        defaultValue: 2.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      n_estimators:
        defaultValue: 100.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      random_state:
        defaultValue: 42.0
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.12.1
